{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Store the training data\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            distances = [self.compute_distance(x, x_train) for x_train in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]  # Get indices of k nearest neighbors\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            predictions.append(np.bincount(k_nearest_labels).argmax())  # Majority vote\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probabilities = []\n",
    "        for x in X:\n",
    "            distances = [self.compute_distance(x, x_train) for x_train in self.X_train]\n",
    "            k_indices = np.argsort(distances)[:self.k]  # Get indices of k nearest neighbors\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "            prob = np.mean(k_nearest_labels)  # Calculate the proportion of churned customers\n",
    "            probabilities.append(prob)\n",
    "        return np.array(probabilities)\n",
    "\n",
    "    def compute_distance(self, X1, X2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.sqrt(np.sum((X1 - X2) ** 2))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(X1 - X2))\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_data, test_data):\n",
    "    y_train = train_data['Exited']\n",
    "    X_train = train_data.drop(columns=['Exited', 'id', 'CustomerId', 'Surname'])\n",
    "    test_data = test_data.drop(columns=['id', 'CustomerId', 'Surname'])\n",
    "\n",
    "    # Fill missing values\n",
    "    X_train.fillna(X_train.median(numeric_only=True), inplace=True)\n",
    "    test_data.fillna(test_data.median(numeric_only=True), inplace=True)\n",
    "\n",
    "    # Encode categorical features\n",
    "    X_train = pd.get_dummies(X_train, columns=['Geography', 'Gender'], drop_first=True)\n",
    "    test_data = pd.get_dummies(test_data, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "    # Align the columns\n",
    "    X_train, test_data = X_train.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "    # Scale numerical features\n",
    "    numerical_features = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "    X_train[numerical_features] = (X_train[numerical_features] - X_train[numerical_features].mean()) / X_train[numerical_features].std()\n",
    "    test_data[numerical_features] = (test_data[numerical_features] - test_data[numerical_features].mean()) / test_data[numerical_features].std()\n",
    "\n",
    "    # Ensure all columns are numeric and convert to numpy arrays\n",
    "    X_train = X_train.apply(pd.to_numeric, errors='coerce').values  # Convert to numpy array\n",
    "    test_data = test_data.apply(pd.to_numeric, errors='coerce').values  # Convert to numpy array\n",
    "\n",
    "    return X_train, y_train.values, test_data  # Convert y_train to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    fold_size = len(X) // n_splits\n",
    "    auc_scores = []\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        # Split data manually\n",
    "        X_train = np.concatenate((X[:i * fold_size], X[(i + 1) * fold_size:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]), axis=0)\n",
    "        X_val = X[i * fold_size:(i + 1) * fold_size]\n",
    "        y_val = y[i * fold_size:(i + 1) * fold_size]\n",
    "\n",
    "        # Train and predict\n",
    "        knn.fit(X_train, y_train)\n",
    "        predictions = knn.predict(X_val)\n",
    "        \n",
    "        # Simplified accuracy calculation for validation purposes\n",
    "        accuracy = np.mean(predictions == y_val)\n",
    "        auc_scores.append(accuracy)\n",
    "\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15000, 11), X_train type: <class 'numpy.ndarray'>\n",
      "y_train shape: (15000,), y_train type: <class 'numpy.ndarray'>\n",
      "X_test shape: (10000, 11), X_test type: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7n/5qt32vwj0fz9g0p7sgzb57jh0000gn/T/ipykernel_50701/1546603925.py:19: DeprecationWarning: Non-integer input passed to bincount. In a future version of NumPy, this will be an error. (Deprecated NumPy 2.1)\n",
      "  predictions.append(np.bincount(k_nearest_labels).argmax())  # Majority vote\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: 0.8768666666666667\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "X, y, X_test = preprocess_data(train_data, test_data)\n",
    "\n",
    "# Check shapes and types instead of dtypes\n",
    "print(f\"X_train shape: {X.shape}, X_train type: {type(X)}\")\n",
    "print(f\"y_train shape: {y.shape}, y_train type: {type(y)}\")\n",
    "print(f\"X_test shape: {X_test.shape}, X_test type: {type(X_test)}\")\n",
    "\n",
    "# Create and evaluate model\n",
    "knn = KNN(k=5, distance_metric='euclidean')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_validate(X, y, knn)\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# Train on full dataset and make predictions on test set\n",
    "knn.fit(X, y)\n",
    "test_probabilities = knn.predict_proba(X_test)\n",
    "\n",
    "# Save test predictions to CSV\n",
    "submission = pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_probabilities})\n",
    "submission.to_csv('submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
